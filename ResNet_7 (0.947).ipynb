{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c834cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae1d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 07:33:46.361297: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# importing layers from keras\n",
    "from keras.layers import Dense, InputLayer, BatchNormalization, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "#for instantiating the model and loading the weights and biases\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "# importing adam optimizer from tensorflow keras optimizer module \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# defining model checkpointing\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "# importing ImageDataGererator for loading images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train_test_split to create training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# accuracy_score to calculate the accuracy of predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c6d07",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf47e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/sceneclassificationdataset/train.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11bdb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3037\n",
       "2    2957\n",
       "5    2883\n",
       "4    2784\n",
       "1    2745\n",
       "0    2628\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e84efd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f46f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data between classes is well distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23eff21",
   "metadata": {},
   "source": [
    "### Creating Training and Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1436a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random number generator\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b8621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a training and validation set\n",
    "train_data, validation_data = train_test_split(data,test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556bb2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11923, 2), (5111, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of training and validation set\n",
    "train_data.shape, validation_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78426d9e",
   "metadata": {},
   "source": [
    "### Image Aumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8978f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "train_datagen = ImageDataGenerator(rotation_range=5,  # rotation\n",
    "                                   width_shift_range=0.2,  # horizontal shift\n",
    "                                   zoom_range=0.2,  # zoom\n",
    "                                   horizontal_flip=True,  # horizontal flip\n",
    "                                   brightness_range=[0.2,0.8],  # brightness\n",
    "                                   rescale=1./255, # normalize data\n",
    "                                   shear_range=0.2) \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d2f1b",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35017770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set Directory\n",
    "path = 'datasets/sceneclassificationdataset/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2528f408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11923 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "train=train_datagen.flow_from_dataframe(dataframe = train_data,           # Training Dataframe\n",
    "                                      directory=path,                   # Training set Directory\n",
    "                                      batch_size=20,                    # Size of Batch\n",
    "                                      class_mode=\"categorical\",         # Type of Labels\n",
    "                                      x_col=\"image_name\",               # Input Column\n",
    "                                      \n",
    "                                      y_col=\"label\",                    # Target Column\n",
    "                                      color_mode=\"rgb\",                 # Image Format\n",
    "                                      target_size=(224,224))            # Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "852bcf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5111 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# load validation data\n",
    "valid = test_datagen.flow_from_dataframe(dataframe = validation_data,    # Validation Dataframe\n",
    "                                    directory=path,                 # Validation set Directory\n",
    "                                    batch_size=20,                  # Size of Batch\n",
    "                                    class_mode=\"categorical\",       # Type of Labels\n",
    "                                    x_col=\"image_name\",             # Input Column\n",
    "                                    color_mode=\"rgb\",               # Image Format\n",
    "                                    y_col=\"label\",                  # Target Column\n",
    "                                    target_size=(224,224))          # Image Size\n",
    "                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5bdb6d",
   "metadata": {},
   "source": [
    "### Load weights from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48eb4614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3295"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use garbage collector to prevent memory error\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "007a2487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 07:34:02.021226: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-19 07:34:02.096144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:1d:00.0 name: Quadro RTX 5000 computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-01-19 07:34:02.096209: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-19 07:34:02.102183: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-19 07:34:02.102266: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-01-19 07:34:02.105011: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-19 07:34:02.105435: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-19 07:34:02.106625: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcutensor.so.1\n",
      "2022-01-19 07:34:02.107435: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-01-19 07:34:02.108722: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-01-19 07:34:02.108944: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-19 07:34:02.111983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-19 07:34:02.114600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:1d:00.0 name: Quadro RTX 5000 computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 15.75GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2022-01-19 07:34:02.117563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2022-01-19 07:34:02.117619: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-19 07:34:02.712668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-19 07:34:02.712708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-01-19 07:34:02.712716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-01-19 07:34:02.716995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14809 MB memory) -> physical GPU (device: 0, name: Quadro RTX 5000, pci bus id: 0000:1d:00.0, compute capability: 7.5)\n",
      "2022-01-19 07:34:02.717452: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 7. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# load weights and model structure from ResNet152V2\n",
    "base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34c1560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show models structure\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8224b7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing all layers other than last 15 Layers\n",
    "for layer in base_model.layers[:-15]:       \n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f78b217",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "output = Dense(units=6, activation='softmax')(x)\n",
    "model = Model(base_model.input, output)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6225145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a5208",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87f90577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the path to save the model\n",
    "path = 'best_model_resnet_7.hdf5'\n",
    "\n",
    "# defining model checkpointing\n",
    "checkpoint = ModelCheckpoint(path, monitor='val_accuracy', verbose = 1, save_best_only = True, mode='max')\n",
    "\n",
    "# defining model early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', verbose = 1, min_delta=0.0001, patience=6, mode='max')\n",
    "\n",
    "# reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5,  verbose = 1)\n",
    "\n",
    "# defining callback list\n",
    "callback_list = [checkpoint, early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75c0cf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 07:34:26.985729: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-19 07:34:27.005828: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2100000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 07:35:08.086351: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-01-19 07:35:08.741030: I tensorflow/stream_executor/cuda/cuda_dnn.cc:380] Loaded cuDNN version 8202\n",
      "2022-01-19 07:35:09.476791: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublas.so.11\n",
      "2022-01-19 07:35:10.082050: I tensorflow/stream_executor/platform/default/dso_loader.cc:54] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597/597 [==============================] - 231s 314ms/step - loss: 0.1854 - accuracy: 0.9431 - val_loss: 0.3089 - val_accuracy: 0.9249\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.92487, saving model to best_model_resnet_7.hdf5\n",
      "Epoch 2/50\n",
      "597/597 [==============================] - 177s 296ms/step - loss: 0.1899 - accuracy: 0.9424 - val_loss: 0.3184 - val_accuracy: 0.9300\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.92487 to 0.92996, saving model to best_model_resnet_7.hdf5\n",
      "Epoch 3/50\n",
      "597/597 [==============================] - 178s 299ms/step - loss: 0.2006 - accuracy: 0.9416 - val_loss: 0.2886 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.92996\n",
      "Epoch 4/50\n",
      "597/597 [==============================] - 178s 298ms/step - loss: 0.1570 - accuracy: 0.9501 - val_loss: 0.3526 - val_accuracy: 0.9323\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.92996 to 0.93230, saving model to best_model_resnet_7.hdf5\n",
      "Epoch 5/50\n",
      "597/597 [==============================] - 177s 297ms/step - loss: 0.1936 - accuracy: 0.9516 - val_loss: 0.3261 - val_accuracy: 0.9210\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.93230\n",
      "Epoch 6/50\n",
      "597/597 [==============================] - 176s 295ms/step - loss: 0.1316 - accuracy: 0.9539 - val_loss: 0.3273 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.93230\n",
      "Epoch 7/50\n",
      "597/597 [==============================] - 177s 297ms/step - loss: 0.1381 - accuracy: 0.9536 - val_loss: 0.3267 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.93230\n",
      "Epoch 8/50\n",
      "597/597 [==============================] - 178s 298ms/step - loss: 0.1242 - accuracy: 0.9609 - val_loss: 0.3533 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.93230\n",
      "Epoch 9/50\n",
      "597/597 [==============================] - 177s 297ms/step - loss: 0.1179 - accuracy: 0.9619 - val_loss: 0.3560 - val_accuracy: 0.9174\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.93230\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 10/50\n",
      "597/597 [==============================] - 177s 296ms/step - loss: 0.0891 - accuracy: 0.9723 - val_loss: 0.3593 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.93230\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# training the model for 50 epochs\n",
    "model_history = model.fit(train, epochs=50, validation_data=valid, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50024cc5",
   "metadata": {},
   "source": [
    "### Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9efd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model_resnet_7.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18bb8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597/597 [==============================] - 152s 255ms/step - loss: 0.0998 - accuracy: 0.9668\n",
      "Test score: 0.09976115822792053\n",
      "Test accuracy: 0.9667868614196777\n"
     ]
    }
   ],
   "source": [
    "# accuracy on training set\n",
    "score, acc = model.evaluate(train)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87b4bc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 24s 93ms/step - loss: 0.3526 - accuracy: 0.9323\n",
      "Test score: 0.3525985777378082\n",
      "Test accuracy: 0.9323028922080994\n"
     ]
    }
   ],
   "source": [
    "# accuracy on validation set\n",
    "score, acc = model.evaluate(valid)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54caf212",
   "metadata": {},
   "source": [
    "### Evaluating model performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "517008a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_data = pd.read_csv('datasets/sceneclassificationdataset/test_Dg8GF4p.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0605abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "049f9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list to store the images\n",
    "X_test = []\n",
    "# iterating over each image\n",
    "for img_name in test_data.image_name:\n",
    "    # loading the image using its name\n",
    "    img = Image.open('datasets/sceneclassificationdataset/train/' + img_name)\n",
    "    # reshape image to (224,224)\n",
    "    img = img.resize((224,224))\n",
    "    a = np.asarray(img)   \n",
    "    # change images with 2 channels to 3\n",
    "    if a.shape != (224,224, 3):\n",
    "        a = cv2.cvtColor(a, cv2.COLOR_GRAY2RGB)\n",
    "    # saving each image in the list\n",
    "    X_test.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "659e3dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the list of images into array\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44c14263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize X_test\n",
    "X_test = X_test /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66146fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict classes for test data\n",
    "predict = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e9e822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column label with predictions\n",
    "test_data['label'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6591d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to csv\n",
    "test_data.to_csv('resnet_7.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
